{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import click\n",
    "import logging\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import json\n",
    "import pathlib \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(pathlib.Path(\"C:/Users/Paulius/p160m138-2019r-lab3/p160m138-2019r-lab3/data/interim/bank_train.csv\"))\n",
    "df_test = pd.read_csv(pathlib.Path(\"C:/Users/Paulius/p160m138-2019r-lab3/p160m138-2019r-lab3/data/interim/bank_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'balance',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'day',\n",
       " 'month',\n",
       " 'duration',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'poutcome',\n",
       " 'target']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "job          object\n",
       "marital      object\n",
       "education    object\n",
       "default      object\n",
       "balance       int64\n",
       "housing      object\n",
       "loan         object\n",
       "contact      object\n",
       "day           int64\n",
       "month        object\n",
       "duration      int64\n",
       "campaign      int64\n",
       "pdays         int64\n",
       "previous      int64\n",
       "poutcome     object\n",
       "target        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    'age',\n",
    "    'balance',\n",
    "    'day',\n",
    "    'campaign',\n",
    "    'pdays',\n",
    "    'previous',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    'job',\n",
    "    'marital',\n",
    "    'education',\n",
    "    'default',\n",
    "    'housing',\n",
    "    'loan',\n",
    "    'contact',\n",
    "    'month',\n",
    "    'campaign',\n",
    "    'poutcome'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor_pipe = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_pipe, numeric_features),\n",
    "        ('cat', categorical_transformer_pipe, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('target', axis=1)\n",
    "y_train = df_train['target']\n",
    "\n",
    "X_test = df_test.drop('target', axis=1)\n",
    "y_test = df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='median',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_pipe),\n",
    "    ('classifier', RandomForestClassifier(n_jobs=-1, n_estimators=100))])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.897\n"
     ]
    }
   ],
   "source": [
    "print(\"model score: {:.3f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.897\n",
      "model precision: 0.674\n",
      "model recall: 0.233\n",
      "model F1: 0.346\n",
      "model AuROC: 0.609\n"
     ]
    }
   ],
   "source": [
    "print(\"model accuracy: {:.3f}\".format(metrics.accuracy_score(y_test, clf.predict(X_test))))\n",
    "\n",
    "print(\"model precision: {:.3f}\".format(metrics.precision_score(y_test, clf.predict(X_test))))\n",
    "\n",
    "print(\"model recall: {:.3f}\".format(metrics.recall_score(y_test, clf.predict(X_test))))\n",
    "\n",
    "print(\"model F1: {:.3f}\".format(metrics.f1_score(y_test, clf.predict(X_test))))\n",
    "\n",
    "print(\"model AuROC: {:.3f}\".format(metrics.roc_auc_score(y_test, clf.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.94      7985\n",
      "           1       0.67      0.23      0.35      1058\n",
      "\n",
      "    accuracy                           0.90      9043\n",
      "   macro avg       0.79      0.61      0.64      9043\n",
      "weighted avg       0.88      0.90      0.87      9043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('num',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value=None,\n",
       "                                                                                                        missing_values=nan,\n",
       "                                                                                                        strategy='medi...\n",
       "                                                               min_impurity_split=None,\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=-1,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'classifier__n_estimators': [10, 30, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='recall', verbose=0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'classifier__n_estimators': [10, 30, 100],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=4, iid=False, scoring='recall', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.897\n",
      "model precision: 0.673\n",
      "model recall: 0.230\n",
      "model F1: 0.342\n",
      "model AuROC: 0.607\n"
     ]
    }
   ],
   "source": [
    "print(\"model accuracy: {:.3f}\".format(metrics.accuracy_score(y_test, grid_search.predict(X_test))))\n",
    "\n",
    "print(\"model precision: {:.3f}\".format(metrics.precision_score(y_test, grid_search.predict(X_test))))\n",
    "\n",
    "print(\"model recall: {:.3f}\".format(metrics.recall_score(y_test, grid_search.predict(X_test))))\n",
    "\n",
    "print(\"model F1: {:.3f}\".format(metrics.f1_score(y_test, grid_search.predict(X_test))))\n",
    "\n",
    "print(\"model AuROC: {:.3f}\".format(metrics.roc_auc_score(y_test, grid_search.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': [3.7253000140190125, 7.2048909068107605, 16.981665909290314],\n",
       " 'std_fit_time': [0.669750416922757, 0.049128142804261525, 0.291984223879611],\n",
       " 'mean_score_time': [3.570048213005066,\n",
       "  0.19624316692352295,\n",
       "  0.2787806987762451],\n",
       " 'std_score_time': [0.6641879251700253,\n",
       "  0.008273285454890745,\n",
       "  0.17175448851807368],\n",
       " 'param_classifier__n_estimators': [10, 30, 100],\n",
       " 'params': [{'classifier__n_estimators': 10},\n",
       "  {'classifier__n_estimators': 30},\n",
       "  {'classifier__n_estimators': 100}],\n",
       " 'split0_test_score': [0.2003780718336484,\n",
       "  0.20132325141776938,\n",
       "  0.21361058601134217],\n",
       " 'split1_test_score': [0.18525519848771266,\n",
       "  0.21455576559546313,\n",
       "  0.21644612476370512],\n",
       " 'split2_test_score': [0.1880907372400756,\n",
       "  0.2060491493383743,\n",
       "  0.21172022684310018],\n",
       " 'split3_test_score': [0.16745506149479658,\n",
       "  0.1750236518448439,\n",
       "  0.1825922421948912],\n",
       " 'mean_test_score': [0.18529476726405833,\n",
       "  0.19923795454911267,\n",
       "  0.20609229495325967],\n",
       " 'std_test_score': [0.011764142472654976,\n",
       "  0.01476235608052919,\n",
       "  0.013671618312954919],\n",
       " 'rank_test_score': [3, 2, 1]}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = {k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in grid_search.cv_results_.items()}\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"mean_fit_time\": [\n",
      "        3.7253000140190125,\n",
      "        7.2048909068107605,\n",
      "        16.981665909290314\n",
      "    ],\n",
      "    \"std_fit_time\": [\n",
      "        0.669750416922757,\n",
      "        0.049128142804261525,\n",
      "        0.291984223879611\n",
      "    ],\n",
      "    \"mean_score_time\": [\n",
      "        3.570048213005066,\n",
      "        0.19624316692352295,\n",
      "        0.2787806987762451\n",
      "    ],\n",
      "    \"std_score_time\": [\n",
      "        0.6641879251700253,\n",
      "        0.008273285454890745,\n",
      "        0.17175448851807368\n",
      "    ],\n",
      "    \"param_classifier__n_estimators\": [\n",
      "        10,\n",
      "        30,\n",
      "        100\n",
      "    ],\n",
      "    \"params\": [\n",
      "        {\n",
      "            \"classifier__n_estimators\": 10\n",
      "        },\n",
      "        {\n",
      "            \"classifier__n_estimators\": 30\n",
      "        },\n",
      "        {\n",
      "            \"classifier__n_estimators\": 100\n",
      "        }\n",
      "    ],\n",
      "    \"split0_test_score\": [\n",
      "        0.2003780718336484,\n",
      "        0.20132325141776938,\n",
      "        0.21361058601134217\n",
      "    ],\n",
      "    \"split1_test_score\": [\n",
      "        0.18525519848771266,\n",
      "        0.21455576559546313,\n",
      "        0.21644612476370512\n",
      "    ],\n",
      "    \"split2_test_score\": [\n",
      "        0.1880907372400756,\n",
      "        0.2060491493383743,\n",
      "        0.21172022684310018\n",
      "    ],\n",
      "    \"split3_test_score\": [\n",
      "        0.16745506149479658,\n",
      "        0.1750236518448439,\n",
      "        0.1825922421948912\n",
      "    ],\n",
      "    \"mean_test_score\": [\n",
      "        0.18529476726405833,\n",
      "        0.19923795454911267,\n",
      "        0.20609229495325967\n",
      "    ],\n",
      "    \"std_test_score\": [\n",
      "        0.011764142472654976,\n",
      "        0.01476235608052919,\n",
      "        0.013671618312954919\n",
      "    ],\n",
      "    \"rank_test_score\": [\n",
      "        3,\n",
      "        2,\n",
      "        1\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# json.dumps converts an object into JSON string, while json.dump writes it to a file\n",
    "print(json.dumps(cv_results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('C:/Users/Paulius/p160m138-2019r-lab3/p160m138-2019r-lab3/notebooks/Notebook/p160m138-2019r-lab3/p160m138-2019r-lab3/json' + 'best_params.json', 'w') as outfile:  \n",
    "   \n",
    "    json.dump(grid_search.best_params_, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'classifier__n_estimators': [10, 30, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20, 30]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('num',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value=None,\n",
       "                                                                                                        missing_values=nan,\n",
       "                                                                                                        strategy='medi...\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=-1,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'classifier__max_depth': [None, 10, 20, 30],\n",
       "                         'classifier__n_estimators': [10, 30, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=5, iid=False, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_res = {\n",
    "        'classifier__n_estimators': grid_search.best_params_['classifier__n_estimators'],\n",
    "        'classifier__max_depth': grid_search.best_params_['classifier__max_depth']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/Paulius/p160m138-2019r-lab3/p160m138-2019r-lab3/notebooks/Notebook/p160m138-2019r-lab3/p160m138-2019r-lab3/json' + 'best_params.json', 'w') as outfile:\n",
    "    json.dump(grid_search.best_params_, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_dict = dict()\n",
    "for key in grid_search.cv_results_.keys():\n",
    "        val = grid_search.cv_results_[key]\n",
    "        converted_val = val\n",
    "        if isinstance(val, np.ndarray):\n",
    "            converted_val = val.tolist()\n",
    "        converted_dict[key] = converted_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/Paulius/p160m138-2019r-lab3/p160m138-2019r-lab3/notebooks/Notebook/p160m138-2019r-lab3/p160m138-2019r-lab3/json' + 'best_params.json', 'w') as outfile:\n",
    "    json.dump(converted_dict, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-93a0039bd16b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmetrics_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmetrics_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m metrics_dict = {\n\u001b[0;32m      4\u001b[0m        \u001b[1;34m'metrics_test'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetrics_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m        \u001b[1;34m'metrics_train'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetrics_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "metrics_test = get_metrics(X_test, y_test, clf)\n",
    "metrics_train = get_metrics(X_train, y_train, clf)\n",
    "metrics_dict = {\n",
    "       'metrics_test': metrics_test,\n",
    "       'metrics_train': metrics_train\n",
    "               }\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
